import requests
import json
import time
import re


class OllamaChatClient:
    def __init__(self, base_url="http://localhost:11434", model="deepseek-r1:8b"):
        self.base_url = base_url
        self.model = model
        self.conversation_history = []
        self.available_tools = self._define_tools()

        # æµå¼è¾“å‡ºé…ç½®
        self.stream_config = {
            'char_delay': 0.08,  # å­—ç¬¦å»¶è¿Ÿï¼ˆç§’ï¼‰
            'sentence_delay': 0.3,  # å¥å­é—´å»¶è¿Ÿï¼ˆç§’ï¼‰
            'comma_delay': 0.15,  # é€—å·å»¶è¿Ÿï¼ˆç§’ï¼‰
        }

        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        self._check_service()

    def set_stream_speed(self, speed='normal'):
        """è®¾ç½®æµå¼è¾“å‡ºé€Ÿåº¦"""
        speeds = {
            'slow': {'char_delay': 0.12, 'sentence_delay': 0.5, 'comma_delay': 0.2},
            'normal': {'char_delay': 0.08, 'sentence_delay': 0.3, 'comma_delay': 0.15},
            'fast': {'char_delay': 0.03, 'sentence_delay': 0.1, 'comma_delay': 0.05}
        }
        if speed in speeds:
            self.stream_config = speeds[speed]
            print(f"âœ… å·²è®¾ç½®è¾“å‡ºé€Ÿåº¦ä¸º: {speed}")

    def _check_service(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                print("âœ… OllamaæœåŠ¡è¿æ¥æ­£å¸¸")
                models = response.json().get('models', [])
                print(f"ğŸ“š å¯ç”¨æ¨¡å‹: {[model['name'] for model in models]}")
                return True
            else:
                print(f"âŒ OllamaæœåŠ¡å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
        except requests.exceptions.ConnectionError:
            print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
            return False
        except Exception as e:
            print(f"âŒ æ£€æŸ¥æœåŠ¡æ—¶å‡ºé”™: {e}")
            return False

    def _define_tools(self):
        """å®šä¹‰å¯ç”¨çš„å·¥å…·æ–¹æ³•"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "get_current_time",
                    "description": "è·å–å½“å‰ç³»ç»Ÿæ—¶é—´",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "calculate_math",
                    "description": "è®¡ç®—æ•°å­¦è¡¨è¾¾å¼",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "expression": {
                                "type": "string",
                                "description": "æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ 2+2, 3*5, 10/2"
                            }
                        },
                        "required": ["expression"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "è·å–å¤©æ°”ä¿¡æ¯",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "åŸå¸‚åç§°"
                            }
                        },
                        "required": ["city"]
                    }
                }
            }
        ]

    def improved_stream_chat(self, message, use_native_tools=True):
        """æ”¹è¿›çš„æµå¼èŠå¤©æ–¹æ³•"""
        try:
            # å¦‚æœä½¿ç”¨åŸç”Ÿå·¥å…·è°ƒç”¨ä¸”æ˜¯8Bæ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨å·¥å…·è°ƒç”¨
            if use_native_tools and "8b" in self.model:
                tool_response = self._try_native_tool_call(message)
                if tool_response:
                    return tool_response

            # å›é€€åˆ°æ‰‹åŠ¨å·¥å…·æ£€æµ‹
            tool_response = self._check_tool_usage(message)
            if tool_response:
                print("ğŸ¤– AI: ", end="", flush=True)
                self._simulate_stream_output(tool_response)
                return tool_response

            # æ„å»ºå¯¹è¯å†å²
            if self.conversation_history:
                messages = self.conversation_history + [{"role": "user", "content": message}]
                data = {
                    "model": self.model,
                    "messages": messages,
                    "stream": True,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "num_predict": 500,
                    }
                }
                endpoint = "/api/chat"
            else:
                data = {
                    "model": self.model,
                    "prompt": message,
                    "stream": True,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "num_predict": 500,
                    }
                }
                endpoint = "/api/generate"

            print("ğŸ¤– AI: ", end="", flush=True)

            response = requests.post(
                f"{self.base_url}{endpoint}",
                json=data,
                stream=True,
                timeout=120
            )

            if response.status_code != 200:
                error_msg = f"APIé”™è¯¯: {response.status_code} - {response.text}"
                print(error_msg)
                return error_msg

            full_response = ""

            for line in response.iter_lines():
                if line:
                    try:
                        chunk = json.loads(line)

                        if endpoint == "/api/chat":
                            if 'message' in chunk and 'content' in chunk['message']:
                                content = chunk['message']['content']
                                self._simulate_stream_output(content)
                                full_response += content

                            if chunk.get('done', False):
                                break

                        else:
                            if 'response' in chunk:
                                content = chunk['response']
                                self._simulate_stream_output(content)
                                full_response += content

                            if chunk.get('done', False):
                                break

                    except json.JSONDecodeError:
                        continue

            print()  # æ¢è¡Œ

            # ä¿å­˜åˆ°å¯¹è¯å†å²
            self.conversation_history.extend([
                {"role": "user", "content": message},
                {"role": "assistant", "content": full_response}
            ])

            return full_response

        except requests.exceptions.Timeout:
            error_msg = "â° è¯·æ±‚è¶…æ—¶"
            print(error_msg)
            return error_msg
        except Exception as e:
            error_msg = f"âŒ è¯·æ±‚å¤±è´¥: {e}"
            print(error_msg)
            return error_msg

    def _try_native_tool_call(self, message):
        """å°è¯•ä½¿ç”¨åŸç”Ÿå·¥å…·è°ƒç”¨ï¼ˆé€‚ç”¨äº8Bæ¨¡å‹ï¼‰"""
        try:
            messages = self.conversation_history + [{"role": "user", "content": message}]

            data = {
                "model": self.model,
                "messages": messages,
                "tools": self.available_tools,
                "stream": True,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                }
            }

            response = requests.post(
                f"{self.base_url}/api/chat",
                json=data,
                stream=True,
                timeout=120
            )

            if response.status_code == 200:
                print("ğŸ¯ ä½¿ç”¨åŸç”Ÿå·¥å…·è°ƒç”¨...")
                return self._handle_native_tool_stream(response, message)
            else:
                print(f"âš ï¸ åŸç”Ÿå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æ‰‹åŠ¨æ£€æµ‹ (çŠ¶æ€ç : {response.status_code})")
                return None

        except Exception as e:
            print(f"âš ï¸ åŸç”Ÿå·¥å…·è°ƒç”¨å¼‚å¸¸: {e}ï¼Œå›é€€åˆ°æ‰‹åŠ¨æ£€æµ‹")
            return None

    def _handle_native_tool_stream(self, response, user_message):
        """å¤„ç†åŸç”Ÿå·¥å…·è°ƒç”¨çš„æµå¼å“åº”"""
        full_response = ""
        tool_calls_detected = False

        print("ğŸ¤– AI: ", end="", flush=True)

        for line in response.iter_lines():
            if line:
                try:
                    chunk = json.loads(line)

                    # æ£€æŸ¥å·¥å…·è°ƒç”¨
                    if 'message' in chunk and 'tool_calls' in chunk['message']:
                        tool_calls_detected = True
                        tool_calls = chunk['message']['tool_calls']

                        for tool_call in tool_calls:
                            tool_name = tool_call['function']['name']
                            tool_args = json.loads(tool_call['function']['arguments'])

                            # æ‰§è¡Œå·¥å…·
                            tool_result = self.execute_tool(tool_name, tool_args)

                            # ä¿å­˜åˆ°å†å²
                            self.conversation_history.extend([
                                {"role": "user", "content": user_message},
                                {"role": "assistant", "content": "", "tool_calls": tool_calls},
                                {"role": "tool", "content": tool_result, "tool_call_id": tool_call.get('id', '')}
                            ])

                            # è·å–æœ€ç»ˆå›å¤
                            print(f"\nğŸ”„ å·¥å…·æ‰§è¡Œå®Œæˆ: {tool_result}")
                            final_response = self._get_final_response_after_tools()
                            return final_response

                    # æ­£å¸¸æ–‡æœ¬è¾“å‡º
                    if 'message' in chunk and 'content' in chunk['message']:
                        content = chunk['message']['content']
                        if content:
                            self._simulate_stream_output(content)
                            full_response += content

                    if chunk.get('done', False) and not tool_calls_detected:
                        self.conversation_history.extend([
                            {"role": "user", "content": user_message},
                            {"role": "assistant", "content": full_response}
                        ])
                        break

                except json.JSONDecodeError:
                    continue

        print()  # æ¢è¡Œ
        return full_response

    def _get_final_response_after_tools(self):
        """åœ¨å·¥å…·è°ƒç”¨åè·å–å®Œæ•´å›å¤"""
        data = {
            "model": self.model,
            "messages": self.conversation_history,
            "stream": True,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
            }
        }

        response = requests.post(
            f"{self.base_url}/api/chat",
            json=data,
            stream=True,
            timeout=120
        )

        final_response = ""
        print("ğŸ¤– AI: ", end="", flush=True)

        for line in response.iter_lines():
            if line:
                try:
                    chunk = json.loads(line)
                    if 'message' in chunk and 'content' in chunk['message']:
                        content = chunk['message']['content']
                        self._simulate_stream_output(content)
                        final_response += content

                    if chunk.get('done', False):
                        # æ›´æ–°å¯¹è¯å†å²
                        for msg in self.conversation_history:
                            if msg.get('role') == 'assistant' and not msg.get('content'):
                                msg['content'] = final_response
                        break

                except json.JSONDecodeError:
                    continue

        print()  # æ¢è¡Œ
        return final_response

    def _check_tool_usage(self, message):
        """æ‰‹åŠ¨æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·"""
        message_lower = message.lower()

        # æ£€æŸ¥æ—¶é—´ç›¸å…³
        time_keywords = ['æ—¶é—´', 'å‡ ç‚¹', 'ç°åœ¨å‡ ç‚¹', 'å½“å‰æ—¶é—´', 'ä»€ä¹ˆæ—¶å€™', 'ä½•æ—¶', 'today', 'time', 'now']
        if any(keyword in message_lower for keyword in time_keywords):
            current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
            return f"æ ¹æ®ç³»ç»Ÿæ—¶é—´ï¼Œç°åœ¨æ˜¯ {current_time}"

        # æ£€æŸ¥æ•°å­¦è®¡ç®—
        math_pattern = r'(\d+[\+\-\*\/]\d+|\d+\.\d+[\+\-\*\/]\d+\.\d+)'
        math_matches = re.findall(math_pattern, message)
        if math_matches:
            try:
                result = eval(math_matches[0])
                return f"è®¡ç®—ç»“æœ: {math_matches[0]} = {result}"
            except:
                pass

        # æ£€æŸ¥æ˜æ˜¾çš„è®¡ç®—é—®é¢˜
        calc_keywords = ['è®¡ç®—', 'ç­‰äºå¤šå°‘', 'æ˜¯å¤šå°‘', 'ç®—ä¸€ä¸‹', 'calculate', 'compute']
        if any(keyword in message_lower for keyword in calc_keywords):
            numbers = re.findall(r'\d+', message)
            if len(numbers) >= 2:
                if 'åŠ ' in message_lower or '+' in message:
                    result = int(numbers[0]) + int(numbers[1])
                    return f"è®¡ç®—ç»“æœ: {numbers[0]} + {numbers[1]} = {result}"
                elif 'å‡' in message_lower or '-' in message:
                    result = int(numbers[0]) - int(numbers[1])
                    return f"è®¡ç®—ç»“æœ: {numbers[0]} - {numbers[1]} = {result}"
                elif 'ä¹˜' in message_lower or '*' in message or 'Ã—' in message:
                    result = int(numbers[0]) * int(numbers[1])
                    return f"è®¡ç®—ç»“æœ: {numbers[0]} Ã— {numbers[1]} = {result}"
                elif 'é™¤' in message_lower or '/' in message or 'Ã·' in message:
                    if int(numbers[1]) != 0:
                        result = int(numbers[0]) / int(numbers[1])
                        return f"è®¡ç®—ç»“æœ: {numbers[0]} Ã· {numbers[1]} = {result:.2f}"
                    else:
                        return "é”™è¯¯: é™¤æ•°ä¸èƒ½ä¸ºé›¶"

        # æ£€æŸ¥å¤©æ°”æŸ¥è¯¢
        weather_keywords = ['å¤©æ°”', 'weather', 'æ°”æ¸©', 'æ¸©åº¦']
        if any(keyword in message_lower for keyword in weather_keywords):
            # ç®€å•æå–åŸå¸‚åï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ç”¨æ›´å¤æ‚çš„æ–¹æ³•ï¼‰
            cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'å—äº¬', 'æˆéƒ½', 'æ­¦æ±‰']
            for city in cities:
                if city in message:
                    return f"{city}çš„å¤©æ°”: æ™´æœ—ï¼Œ25Â°Cï¼Œå¾®é£"
            return "è¯·æŒ‡å®šè¦æŸ¥è¯¢å¤©æ°”çš„åŸå¸‚"

        return None

    def _simulate_stream_output(self, text):
        """æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ˆå¢åŠ å»¶è¿Ÿï¼‰"""
        for char in text:
            print(char, end="", flush=True)

            # æ ¹æ®å­—ç¬¦ç±»å‹è®¾ç½®ä¸åŒå»¶è¿Ÿ
            if char in 'ã€‚ï¼ï¼Ÿ.!?':  # å¥å­ç»“æŸæ ‡ç‚¹
                time.sleep(self.stream_config['sentence_delay'])
            elif char in 'ï¼Œ,ï¼›;':  # é€—å·åˆ†å·
                time.sleep(self.stream_config['comma_delay'])
            else:  # æ™®é€šå­—ç¬¦
                time.sleep(self.stream_config['char_delay'])

    def execute_tool(self, tool_name, arguments):
        """æ‰§è¡Œå·¥å…·æ–¹æ³•"""
        print(f"\nğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {arguments}")

        if tool_name == "get_current_time":
            current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
            return f"å½“å‰æ—¶é—´æ˜¯: {current_time}"

        elif tool_name == "calculate_math":
            try:
                expression = arguments.get("expression", "")
                allowed_chars = set('0123456789+-*/.() ')
                if all(c in allowed_chars for c in expression):
                    result = eval(expression)
                    return f"è®¡ç®—ç»“æœ: {expression} = {result}"
                else:
                    return "é”™è¯¯: è¡¨è¾¾å¼åŒ…å«ä¸å®‰å…¨å­—ç¬¦"
            except Exception as e:
                return f"è®¡ç®—é”™è¯¯: {e}"

        elif tool_name == "get_weather":
            city = arguments.get("city", "æœªçŸ¥åŸå¸‚")
            return f"{city}çš„å¤©æ°”: æ™´æœ—ï¼Œ25Â°Cï¼Œå¾®é£"

        else:
            return f"æœªçŸ¥å·¥å…·: {tool_name}"

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")

    def show_conversation(self):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        if not self.conversation_history:
            print("ğŸ“œ å¯¹è¯å†å²ä¸ºç©º")
            return

        print("\nğŸ“œ å¯¹è¯å†å²:")
        for i, msg in enumerate(self.conversation_history):
            role = msg['role']
            content = msg.get('content', '')
            tool_calls = msg.get('tool_calls', None)

            if role == 'user':
                print(f"ğŸ‘¤ [{i}]: {content}")
            elif role == 'assistant':
                if tool_calls:
                    print(f"ğŸ¤– [{i}]: [å·¥å…·è°ƒç”¨] {content}")
                else:
                    print(f"ğŸ¤– [{i}]: {content}")
            elif role == 'tool':
                print(f"ğŸ”§ [{i}]: å·¥å…·æ‰§è¡Œç»“æœ: {content}")

    def test_tool_capabilities(self):
        """æµ‹è¯•å·¥å…·è°ƒç”¨èƒ½åŠ›"""
        print("\nğŸ§ª æµ‹è¯•å·¥å…·è°ƒç”¨...")

        test_cases = [
            "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ",
            "è®¡ç®—ä¸€ä¸‹ 15 * 8 ç­‰äºå¤šå°‘",
            "åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
        ]

        for i, test_case in enumerate(test_cases, 1):
            print(f"\n{i}. æµ‹è¯•: '{test_case}'")
            self.improved_stream_chat(test_case)


def main():
    # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œé»˜è®¤ä½¿ç”¨8Bæ¨¡å‹
    client = OllamaChatClient(model="deepseek-r1:8b")

    print("\n=== OllamaèŠå¤©å®¢æˆ·ç«¯ (8Bæ¨¡å‹) ===")
    print("ğŸ”§ æ”¯æŒå·¥å…·è°ƒç”¨: æ—¶é—´æŸ¥è¯¢ã€æ•°å­¦è®¡ç®—ã€å¤©æ°”æŸ¥è¯¢")
    print("âš¡ æµå¼è¾“å‡ºé€Ÿåº¦: å¯è°ƒèŠ‚")

    # è®¾ç½®è¾“å‡ºé€Ÿåº¦
    speed = input("è®¾ç½®è¾“å‡ºé€Ÿåº¦ (slow/normal/fast, é»˜è®¤normal): ").strip().lower()
    if speed in ['slow', 'normal', 'fast']:
        client.set_stream_speed(speed)
    else:
        client.set_stream_speed('normal')

    # æµ‹è¯•å·¥å…·èƒ½åŠ›
    client.test_tool_capabilities()

    print("\nğŸ“ å¯ç”¨å‘½ä»¤:")
    print("  - 'clear': æ¸…ç©ºå¯¹è¯å†å²")
    print("  - 'history': æ˜¾ç¤ºå¯¹è¯å†å²")
    print("  - 'quit/exit/é€€å‡º': é€€å‡ºç¨‹åº")
    print("  - 'switch': åˆ‡æ¢æ¨¡å‹")
    print("  - 'speed': è°ƒæ•´è¾“å‡ºé€Ÿåº¦")
    print("  - 'test': é‡æ–°æµ‹è¯•å·¥å…·èƒ½åŠ›")

    while True:
        user_input = input("\nğŸ‘¤ ä½ : ").strip()

        if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
            break
        elif user_input.lower() == 'clear':
            client.clear_history()
            continue
        elif user_input.lower() == 'history':
            client.show_conversation()
            continue
        elif user_input.lower() == 'switch':
            print(f"å½“å‰æ¨¡å‹: {client.model}")
            new_model = input("è¾“å…¥æ–°æ¨¡å‹åç§° (deepseek-r1:1.5b æˆ– deepseek-r1:8b): ").strip()
            if new_model in ['deepseek-r1:1.5b', 'deepseek-r1:8b']:
                client.model = new_model
                print(f"âœ… å·²åˆ‡æ¢åˆ°: {client.model}")
                client.test_tool_capabilities()
            else:
                print("âŒ æ— æ•ˆçš„æ¨¡å‹åç§°")
            continue
        elif user_input.lower() == 'speed':
            speed = input("è®¾ç½®è¾“å‡ºé€Ÿåº¦ (slow/normal/fast): ").strip().lower()
            client.set_stream_speed(speed)
            continue
        elif user_input.lower() == 'test':
            client.test_tool_capabilities()
            continue
        elif not user_input:
            continue

        # å¼€å§‹èŠå¤©
        client.improved_stream_chat(user_input)


if __name__ == "__main__":
    main()